<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Simple Linear Regresion</title>
    <meta charset="utf-8" />
    <meta name="author" content="Pablo E. Gutiérrez-Fonseca" />
    <script src="libs/header-attrs-2.29/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/panelset-0.3.0/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.3.0/panelset.js"></script>
    <script src="libs/fabric-4.3.1/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble-0.0.1/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble-0.0.1/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <script src="libs/mark.js-8.11.1/mark.min.js"></script>
    <link href="libs/xaringanExtra-search-0.0.1/search.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-search-0.0.1/search.js"></script>
    <script>window.addEventListener('load', function() { window.xeSearch = new RemarkSearch({"position":"bottom-left","caseSensitive":false,"showIcon":false,"autoSearch":true}) })</script>
    <script src="libs/xaringanExtra-progressBar-0.0.1/progress-bar.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/xaringanExtra-extra-styles-0.2.6/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script type="application/json" id="xaringanExtra-editable-docid">{"id":"e7bd26c1399643e1b6f08ba062b14775","expires":1}</script>
    <script src="libs/himalaya-1.1.0/himalaya.js"></script>
    <script src="libs/js-cookie-3.0.0/js.cookie.js"></script>
    <link href="libs/editable-0.2.6/editable.css" rel="stylesheet" />
    <script src="libs/editable-0.2.6/editable.js"></script>
    <link rel="stylesheet" href="css/nhsr.css" type="text/css" />
    <link rel="stylesheet" href="css/nhsr-fonts.css" type="text/css" />
    <link rel="stylesheet" href="css/custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Simple Linear Regresion
]
.author[
### Pablo E. Gutiérrez-Fonseca
]
.date[
### 2025-Jan-01 (updated: 2025-Apr-08)
]

---


<style>.xe__progress-bar__container {
  bottom:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 4px;
  background-color: #0051BA;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>

# What is regression?
- Regression analysis is a generic term for a group of different statistical techniques. 

1. The purpose of all these techniques is to examine the relationship between variables. 
      - Regression aims to find the **best-fitting linear equation ( `\(Y = \beta_0 + \beta_1 X_1 + \epsilon\)` )** that describes the relationship between the dependent variable (often denoted as `\(Y\)` ) and independent variables (denoted as `\(X1, X2, ..., Xn\)` ).  
&lt;br&gt;
2. The most common type of linear regression is Type I regression, in which we attempt to determine the relationship between dependent and explanatory or independent variables.

---
## What can we accomplish with linear regression?

.pull-left[
1. Describing the nature of the relationship between two variables.

]


.pull-right[

![](Simple-Linear-Regresion_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;
]


---
## What can we accomplish with linear regression?

.pull-left[
1. Describing the nature of the relationship between two variables.

2. Predicting the dependent variable within the range of observed values. Aim to forecast y-values within the range of observed x-values. Offers relatively more certainty due to reliance on known data.
]


.pull-right[

![](Simple-Linear-Regresion_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;
]


---
## What can we accomplish with linear regression?
.pull-left[
1. Describing the nature of the relationship between two variables.

2. Predicting the dependent variable within the range of observed values. Aim to forecast y-values within the range of observed x-values. Offers relatively more certainty due to reliance on known data.
3. Predicting the dependent variable beyond the range of observed values.
    - Represents an exploration beyond the limits of observed data.
    - Naturally, this type of objective carries the greatest load of restrictions, assumptions, caveats, and risk of error.
]


.pull-right[
![](Simple-Linear-Regresion_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]

---
## Difference Between Correlation and Linear Simple Regression
.left-column[
.blue[**1- Degree &amp; Nature of Relationship:**]

2- Cause &amp; Effect Relationship

3- Independent and Dependent Relationship]

.right-column[
- Correlation is a measure of degree of relationship between X &amp; Y.
- Regression studies the nature of relationship between the variables so that one may be able to predict the value of one variable on the basis of another.]


---
## Difference Between Correlation and Linear Simple Regression
.left-column[
1- Degree &amp; Nature of Relationship

.blue[**2- Cause &amp; Effect Relationship:**]

3- Independent and Dependent Relationship]

.right-column[
- Correlation does **not imply a cause-and-effect relationship** between two variables.
- Regression models a **cause-and-effect relationship**, where:
  - The independent variable ( `\(x\)` ) is the cause.
  - The dependent variable ( `\(y\)` ) is the effect.
]

---
## Difference Between Correlation and Linear Simple Regression
.left-column[
1- Degree &amp; Nature of Relationship

2- Cause &amp; Effect Relationship

### .blue[3- Independent and Dependent Relationship:]
]

.right-column[
- In correlation, there is **no distinction** between independent and dependent variables.
- In regression, the model includes:
    - Slope ( `\(\beta_1\)` ): the change in the dependent variable per unit increase in the independent variable.
    - Intercept ( `\(\beta_0\)` ): the value of the dependent variable when the independent variable is zero.
]


---
# When to use a Simple Linear Regression
- You have two continuous variables measured in the same unit.
- You suspect the variables are related and vary in unison.
- You aim to predict one variable based on the other.
- You want to evaluate a trend (slope) over multiple measurements.


---
# Assumptions 
1. Independent, random samples
2. Linear relationship between variables
3. Normally distributed residuals (after fitting the model)


---
# Building blocks of a linear regression model


---
# Building blocks of a linear regression model
.pull-left[
- **Create a Predictive Equation**:
  - Develop an equation for a line that most accurately predicts the response variable based on the explanatory variable.

- **Evaluate the Model**:
  - Quantify how well the line fits the data (e.g., using metrics like `\(R^2\)` or residual analysis).
    - Assess the model's predictive power and understand its limitations in making predictions beyond the observed data.]

---
# Building blocks of a linear regression model

.pull-left[
- **Create a Predictive Equation**:  
    - Develop an equation for a line that most accurately predicts the response variable based on the explanatory variable.
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;
]


---
# Building blocks of a linear regression model

.pull-left[
- **Create a Predictive Equation**: 
    - Develop an equation for a line that most accurately predicts the response variable based on the explanatory variable.
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Building blocks of a linear regression model

.pull-left[
- **Create a Predictive Equation**: 
    - Develop an equation for a line that most accurately predicts the response variable based on the explanatory variable.
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Building blocks of a linear regression model

.pull-left[
- **Create a Predictive Equation**: 
    - Develop an equation for a line that most accurately predicts the response variable based on the explanatory variable.
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Building blocks of a linear regression model

.pull-left[
- **Create a Predictive Equation**: 
    - Develop an equation for a line that most accurately predicts the response variable based on the explanatory variable.
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;
]


---
# Building blocks of a linear regression model

.pull-left[
- **Create a Predictive Equation**: 
    - Develop an equation for a line that most accurately predicts the response variable based on the explanatory variable.
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Building blocks of a linear regression model

.pull-left[
- **Create a Predictive Equation**: 
    - Develop an equation for a line that most accurately predicts the response variable based on the explanatory variable.
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Building blocks of a linear regression model

.pull-left[
- Calculate the model parameters (**intercept** and **slope**) for the line that cuts through the observations with the **least amount of error (squared error)**.  
  -   This is referred to as a **Least Squares Regression (LSR)**.

- LSR does this by minimizing the sum of the squares of the differences between the observed dependent variable values and those predicted by the linear model. 
    - These differences are called **residuals**.

]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Building blocks of a linear regression model

.pull-left[
- The sum of squared error in regression is:

`$$\text{SSE} = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^{n} (y - \hat{y})^2$$`
]

---
# Building blocks of a linear regression model

.pull-left[
- The sum of squared error in regression is:

`$$\text{SSE} = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^{n} (y - \hat{y})^2$$`
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-13-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Building blocks of a linear regression model

.pull-left[
- The sum of squared error in regression is:

`$$\text{SSE} = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^{n} (y - \hat{y})^2$$`
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;
]


---
# Building blocks of a linear regression model

.pull-left[
- The sum of squared error in regression is:

`$$\text{SSE} = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^{n} (y - \hat{y})^2$$`
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-15-1.png" style="display: block; margin: auto;" /&gt;
]


---
# Building blocks of a linear regression model

.pull-left[
- The sum of squared error in regression is:

`$$\text{SSE} = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^{n} (y - \hat{y})^2$$`
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /&gt;
]



---
# Building blocks of a linear regression model
.pull-left[
- The sum of squared error in regression is:

`$$\text{SSE} = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^{n} (y - \hat{y})^2$$`
]


.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-17-1.png" style="display: block; margin: auto;" /&gt;
]



---
# Building blocks of a linear regression model

.pull-left[
- **Best fit** in context of OLS (Ordinary Least Square, a type of Least Square) means that the sum of the squares of the residuals (or error SSE) us as **small as possible**.

- Mathematically, it's about finding the values of slope ( `\(\beta_1\)`, `\(\beta_2\)`, ., `\(\beta_n\)` ) that minimize this sum.
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-18-1.png"  /&gt;
]


---
# Building blocks of a linear regression model

.pull-left[
- **Slopes**
]

---
# Building blocks of a linear regression model

.pull-left[
- **Slopes** ( `\(\beta_1\)`, `\(\beta_2\)`, ., `\(\beta_n\)` ): These coefficients represent the **change in the dependent variable for a one-unit change in the corresponding independent variable**, holding other variables constant.
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-19-1.png"  /&gt;
]



---
# Building blocks of a linear regression model

.pull-left[
- **Slopes** ( `\(\beta_1\)`, `\(\beta_2\)`, ., `\(\beta_n\)` ): These coefficients represent the **change in the dependent variable for a one-unit change in the corresponding independent variable**, holding other variables constant.


&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-20-1.png"  /&gt;
]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-21-1.png"  /&gt;
]


---
# Building blocks of a linear regression model

.pull-left[
- **Slopes** ( `\(\beta_1\)`, `\(\beta_2\)`, ., `\(\beta_n\)` ): These coefficients represent the **change in the dependent variable for a one-unit change in the corresponding independent variable**, holding other variables constant.

- The slope ( `\(\beta_1\)` ) of your line:
  - It tells you how much will Y increase with each unit increase in X.
  - This is what you are interested in when examining trends over time (X).

]

.pull-right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-22-1.png"  /&gt;
]


---
# Explanation of Terms

`$$y_i = \underbrace{\beta_0}_{\text{Intercept}} + \underbrace{\beta_1}_{\text{Slope}} x_i + \underbrace{\epsilon_i}_{\text{Error}}$$`

--

- ** `\(y_i\)` ** (Predicted Response Variable): The estimated or predicted value of the response variable.

--

- ** `\(\beta_0\)` ** (Intercept): Represents the value of `\(y\)` when `\(x\)` is zero, or where it crosses the y axis

--

- ** `\(\beta_1\)` **  (Slope): Represents the change in `\(y\)` for a one-unit increase in `\(x\)`, showing the steepness and direction of the line.

--

- ** `\(x_i\)` **  (Predictor Variable): The measured value of the independent variable.

--

- ** `\(\epsilon_i\)` ** (Error Term): Accounts for variability in `\(y\)` not explained by `\(x\)`, reflecting factors not captured in the model.

---
# Explanation of Terms: Example


---
# Explanation of Terms: Example
.pull-left[$$y_i = {\beta_0} + {\beta_1} x_i + {\epsilon_i}$$ 

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

`\(\beta_1 = \frac{n \sum(xy) - \left( \sum x \right) \left( \sum y \right)}{n \sum(x^2) - \left( \sum x \right)^2}\)`

&lt;br&gt;
&lt;br&gt;

`\(\beta_0 = \frac{\sum y}{n} - \beta_1 \frac{\sum x}{n}\)`

]

.pull-right[.pull-right[
|  x   |     y     |
|------|-----------|
|  1   |   3      |
|  2   |   5      |
|  3   |   9      |
|  4   |  13      |
|  5   |  12      |
|  6   |  15      |
|  7   |  21      |
|  8   |  22      |
|  9   |  22      |
| 10   |  26      |
]]

---
# Explanation of Terms: Example
.pull-left[$$y_i = {\beta_0} + {\beta_1} x_i + {\epsilon_i}$$ 

&lt;br&gt;
`\(\sum x = 55, \sum y = 127, \sum (xy) = 1008, \sum x^2 = 3025\)`

&lt;br&gt;

`\(\beta_1 = \frac{n \sum(xy) - \left( \sum x \right) \left( \sum y \right)}{n \sum(x^2) - \left( \sum x \right)^2} \Rightarrow\)`

&lt;br&gt;
&lt;br&gt;

`\(\beta_0 = \frac{\sum y}{n} - \beta_1 \frac{\sum x}{n} \Rightarrow\)`
]

.pull-right[.pull-right[
|  x   |     y     |   X*Y    |
|------|-----------|----------|
|  1   |   3      |   3      |
|  2   |   5      |   9      |
|  3   |   9      |   26     |
|  4   |  13      |   52     |
|  5   |  12      |   60     |
|  6   |  15      |   87     |
|  7   |  21      |   145    |
|  8   |  22      |   172    |
|  9   |  22      |   194    |
| 10   |  26      |   261    |
| **55** | **127**  | **1008** |
]]


---
# Explanation of Terms: Example
.pull-left[$$y_i = {\beta_0} + {\beta_1} x_i + {\epsilon_i}$$ 

&lt;br&gt;
`\(\sum x = 55, \sum y = 127, \sum (xy) = 1008, \sum x^2 = 3025\)`

&lt;br&gt;

`\(\beta_1 = \frac{n \sum(xy) - \left( \sum x \right) \left( \sum y \right)}{n \sum(x^2) - \left( \sum x \right)^2} \Rightarrow \beta_1 = \frac{10 \times 1008 - 55 \times 127}{10 \times 3025 - 55^2}= 2.53\)`

&lt;br&gt;
&lt;br&gt;

`\(\beta_0 = \frac{\sum y}{n} - \beta_1 \frac{\sum x}{n} \Rightarrow\)`
]

.pull-right[.pull-right[
|  x   |     y     |   X*Y    |
|------|-----------|----------|
|  1   |   3      |   3      |
|  2   |   5      |   9      |
|  3   |   9      |   26     |
|  4   |  13      |   52     |
|  5   |  12      |   60     |
|  6   |  15      |   87     |
|  7   |  21      |   145    |
|  8   |  22      |   172    |
|  9   |  22      |   194    |
| 10   |  26      |   261    |
| **55** | **127**  | **1008** |
]]


---
# Explanation of Terms: Example
.pull-left[$$y_i = {\beta_0} + {\beta_1} x_i + {\epsilon_i}$$ 

&lt;br&gt;
`\(\sum x = 55, \sum y = 127, \sum (xy) = 1008, \sum x^2 = 3025\)`

&lt;br&gt;

`\(\beta_1 = \frac{n \sum(xy) - \left( \sum x \right) \left( \sum y \right)}{n \sum(x^2) - \left( \sum x \right)^2} \Rightarrow \beta_1 = \frac{10 \times 1008 - 55 \times 127}{10 \times 3025 - 55^2}= 2.53\)`

&lt;br&gt;
&lt;br&gt;

`\(\beta_0 = \frac{\sum y}{n} - \beta_1 \frac{\sum x}{n} \Rightarrow \beta_0 = \frac{127}{10} - 2.53 \times \frac{55}{10} = 0.87\)`

]

.pull-right[.pull-right[
|  x   |     y     |   X*Y    |
|------|-----------|----------|
|  1   |   3      |   3      |
|  2   |   5      |   9      |
|  3   |   9      |   26     |
|  4   |  13      |   52     |
|  5   |  12      |   60     |
|  6   |  15      |   87     |
|  7   |  21      |   145    |
|  8   |  22      |   172    |
|  9   |  22      |   194    |
| 10   |  26      |   261    |
| **55** | **127**  | **1008** |
]]




---
# Explanation of Terms: Example
.pull-left[$$y_i = {\beta_0} + {\beta_1} x_i + {\epsilon_i}$$ 

&lt;br&gt;
`\(\sum x = 55, \sum y = 127, \sum (xy) = 1008, \sum x^2 = 3025\)`

&lt;br&gt;

`\(\beta_1 = \frac{n \sum(xy) - \left( \sum x \right) \left( \sum y \right)}{n \sum(x^2) - \left( \sum x \right)^2} \Rightarrow \beta_1 = \frac{10 \times 1008 - 55 \times 127}{10 \times 3025 - 55^2}= 2.53\)`

&lt;br&gt;
&lt;br&gt;

`\(\beta_0 = \frac{\sum y}{n} - \beta_1 \frac{\sum x}{n} \Rightarrow \beta_0 = \frac{127}{10} - 2.53 \times \frac{55}{10} = 0.87\)`

]


.pull-right[.right[
&lt;img src="Simple-Linear-Regresion_files/figure-html/unnamed-chunk-23-1.png" style="display: block; margin: auto;" /&gt;
]
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
  "highlightLanguage": "r",
  "highlightStyle": "github",
  "highlightLines": true,
  "highlightSpans": true,
  "countIncrementalSlides": true,
  "ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url(css/logo.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 110px;
  height: 128px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    // ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
